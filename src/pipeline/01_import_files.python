# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------


from datetime import datetime
from dateutil.relativedelta import relativedelta


data_file_types = ['fhv_tripdata', 'fhvhv_tripdata', 'green_tripdata',  'yellow_tripdata']

volume_path = '/Volumes/workspace/01_transient/new_york_trips'

start_date = datetime(year=2023, month=1, day=1)
end_date = datetime(year=2023, month=5, day=1)

spark.sql("USE CATALOG `workspace`;")
spark.sql("USE SCHEMA `01_transient`;")

for file_types in data_file_types:
    date_to_ingest = start_date
    while date_to_ingest <= end_date:
        file_name = f"{volume_path}/{file_types}_{date_to_ingest.year}-{date_to_ingest.month:02}.parquet"
        table_name = f"workspace.01_transient.{file_types}_{date_to_ingest.year}_{date_to_ingest.month:02}".strip()

        sql = f"CREATE OR REPLACE TABLE {table_name} TBLPROPERTIES ('delta.feature.timestampNtz' = 'supported') AS SELECT * FROM PARQUET.`{file_name}`;"

        spark.sql(sql)

        print(f"{file_name} imported")

        date_to_ingest = date_to_ingest + relativedelta(months=1)